adjust = .5,
## adjust height
width = .6,
## set slab interval to show IQR and 95% data range
.width = c(.5, .95)
## move geom to the right
justification = -.2,
## remove slab interval
.width = 0,
point_colour = NA
)
# NOTE: I'd say effect is more observed for the sad faces.
# KEY: If I were to ran the analyses on the sad faces only, do I see significant
# difference between the audio conditions?
#### FIGURE 1 ####
# see side-by-side
ggplot(tmpdata, aes(x=variable,y=deltaCategory,fill=factor(audio_type)))+
geom_boxplot() + labs(title="Delta -> Crowd - Single", x = "AUDIO TYPES 1: Crowd_H, 2: Noise, 3: Crowd_L", y = "response from 1-10; 5 equals 'neutral'") +
facet_wrap(~audio_type)+
## add dot plots from {ggdist} package
ggdist::stat_dots(
## orientation to the left
side = "left",
## move geom to the left
justification = 1.0,
## adjust grouping (binning) of observations
binwidth = .15
)+
ggdist::stat_halfeye(
## custom bandwidth
adjust = .5,
## adjust height
width = .6,
## set slab interval to show IQR and 95% data range
.width = c(.5, .95),
## move geom to the right
justification = -.2,
## remove slab interval
.width = 0,
point_colour = NA
)
# NOTE: I'd say effect is more observed for the sad faces.
# KEY: If I were to ran the analyses on the sad faces only, do I see significant
# difference between the audio conditions?
#### FIGURE 1 ####
# see side-by-side
ggplot(tmpdata, aes(x=variable,y=deltaCategory,fill=factor(audio_type)))+
geom_boxplot() + labs(title="Delta -> Crowd - Single", x = "AUDIO TYPES 1: Crowd_H, 2: Noise, 3: Crowd_L", y = "response from 1-10; 5 equals 'neutral'") +
facet_wrap(~audio_type)+
## add dot plots from {ggdist} package
ggdist::stat_dots(
## orientation to the left
side = "left",
## move geom to the left
justification = 1.0,
## adjust grouping (binning) of observations
binwidth = .15
)+
ggdist::stat_halfeye(
## custom bandwidth
adjust = .5,
## adjust height
width = .6,
## set slab interval to show IQR and 95% data range
.width = c(.5, .95),
## move geom to the right
justification = -.2,
## remove slab interval
.width = 0,
point_colour = NA
)
# NOTE: I'd say effect is more observed for the sad faces.
# KEY: If I were to ran the analyses on the sad faces only, do I see significant
# difference between the audio conditions?
#### FIGURE 1 ####
# see side-by-side
ggplot(tmpdata, aes(x=variable,y=deltaCategory,fill=factor(audio_type)))+
geom_boxplot() + labs(title="Delta -> Crowd - Single", x = "AUDIO TYPES 1: Crowd_H, 2: Noise, 3: Crowd_L", y = "response from 1-10; 5 equals 'neutral'") +
facet_wrap(~audio_type)+
## add dot plots from {ggdist} package
ggdist::stat_dots(
## orientation to the left
side = "left",
## move geom to the left
justification = 1.0,
## adjust grouping (binning) of observations
binwidth = .15
)+
ggdist::stat_halfeye(
## custom bandwidth
adjust = .5,
## adjust height
width = .6,
## move geom to the right
justification = -.2,
## remove slab interval, .0, or this:    ## set slab interval to show IQR and 95% data range
.width = c(.5, .95),
point_colour = NA
)
# NOTE: I'd say effect is more observed for the sad faces.
# KEY: If I were to ran the analyses on the sad faces only, do I see significant
# difference between the audio conditions?
#### FIGURE 1 ####
# see side-by-side
ggplot(tmpdata, aes(x=variable,y=deltaCategory,fill=factor(audio_type)))+
geom_boxplot() + labs(title="Delta -> Crowd - Single", x = "AUDIO TYPES 1: Crowd_H, 2: Noise, 3: Crowd_L", y = "response from 1-10; 5 equals 'neutral'") +
facet_wrap(~audio_type)+
## add dot plots from {ggdist} package
ggdist::stat_dots(
## orientation to the left
side = "left",
## move geom to the left
justification = 1.0,
## adjust grouping (binning) of observations
binwidth = .15
)+
ggdist::stat_halfeye(
## custom bandwidth
adjust = .5,
## adjust height
width = .6,
## move geom to the right
justification = -.2,
## remove slab interval, .0, or this:    ## set slab interval to show IQR and 95% data range
.width = c(.5, .95),
point_colour = NA
)+
geom_point(
## draw horizontal lines instead of points
shape = 95,
size = 10,
alpha = .2
)
# NOTE: I'd say effect is more observed for the sad faces.
# KEY: If I were to ran the analyses on the sad faces only, do I see significant
# difference between the audio conditions?
#### FIGURE 1 ####
# see side-by-side
ggplot(tmpdata, aes(x=variable,y=deltaCategory,fill=factor(audio_type)))+
geom_boxplot() + labs(title="Delta -> Crowd - Single", x = "AUDIO TYPES 1: Crowd_H, 2: Noise, 3: Crowd_L", y = "response from 1-10; 5 equals 'neutral'") +
facet_wrap(~audio_type)+
## add dot plots from {ggdist} package
ggdist::stat_dots(
## orientation to the left
side = "left",
## move geom to the left
justification = 1.0,
## adjust grouping (binning) of observations
binwidth = .15,
shape = 95,
size = 10,
alpha = .2
)+
ggdist::stat_halfeye(
## custom bandwidth
adjust = .5,
## adjust height
width = .6,
## move geom to the right
justification = -.2,
## remove slab interval, .0, or this:    ## set slab interval to show IQR and 95% data range
.width = c(.5, .95),
point_colour = NA
)
# NOTE: I'd say effect is more observed for the sad faces.
# KEY: If I were to ran the analyses on the sad faces only, do I see significant
# difference between the audio conditions?
#### FIGURE 1 ####
# see side-by-side
ggplot(tmpdata, aes(x=variable,y=deltaCategory,fill=factor(audio_type)))+
geom_boxplot() + labs(title="Delta -> Crowd - Single", x = "AUDIO TYPES 1: Crowd_H, 2: Noise, 3: Crowd_L", y = "response from 1-10; 5 equals 'neutral'") +
facet_wrap(~audio_type)+
## add dot plots from {ggdist} package
ggdist::stat_dots(
## orientation to the left
side = "left",
## move geom to the left
justification = 1.0,
## adjust grouping (binning) of observations
binwidth = .15
)+
ggdist::stat_halfeye(
## custom bandwidth
adjust = .5,
## adjust height
width = .6,
## move geom to the right
justification = -.2,
## remove slab interval, .0, or this:    ## set slab interval to show IQR and 95% data range
.width = c(.5, .95),
point_colour = NA
)+
geom_point(
## draw horizontal lines instead of points
shape = 95,
size = 10,
alpha = .2
)
pwc <- tmpdata %>%
pairwise_t_test(
deltaCategory ~  variable, paired = FALSE,
p.adjust.method = "bonferroni"
)
pwc
# KEY: here the delta negative means responses got sadder with Single -> Crowd,
# and positive means responses got happier with Single -> Crowd.
# Not sure how to do multiple t-test comparison. Maybe JASP can help.
deltaJasp <- tmpdata
library(psych)
describe(deltaJasp)
write.csv(deltaJasp, "deltaJasp.csv")
# Ok didnt really help. Let's just look at the sad faces.
main_aov <- aov(deltaCategory ~ variable  + (variable:audio_type) + Error(participant_ID), data = tmpdata[tmpdata$audio_type==3,]) #groupEffects_audio[!(groupEffects_audio$audio_type == 3),]
# Ok didnt really help. Let's just look at the sad faces.
main_aov <- aov(deltaCategory ~ variable  + (variable:audio_type) + Error(participant_ID), data = tmpdata[!(tmpdata$audio_type==1),]) #groupEffects_audio[!(groupEffects_audio$audio_type == 3),]
summary(main_aov)
# Ok didnt really help. Let's just look at the sad faces.
main_aov <- aov(deltaCategory ~ variable  + (variable:audio_type) + Error(participant_ID), data = tmpdata[!(tmpdata$audio_type==3),]) #groupEffects_audio[!(groupEffects_audio$audio_type == 3),]
summary(main_aov) # removing 1 leads to p=0.08 interaction.
# Ok didnt really help. Let's just look at the sad faces.
main_aov <- aov(deltaCategory ~ variable  + (variable:audio_type) + Error(participant_ID), data = tmpdata[!(tmpdata$audio_type==1),]) #groupEffects_audio[!(groupEffects_audio$audio_type == 3),]
summary(main_aov) # removing 1 leads to p=0.08 interaction.
tmpdata <- aggregate(deltaCategory~ audio_type + variable + participant_ID, groupEffects_audio_long,mean)
t.test(tmpdata$deltaCategory[tmpdata$audio_type== 2 & tmpdata$variable== "deltaHappy"],
tmpdata$deltaCategory[tmpdata$audio_type== 3 & tmpdata$variable== "deltaHappy"])
t.test(tmpdata$deltaCategory[tmpdata$audio_type== 2 & tmpdata$variable== "deltaSad"],
tmpdata$deltaCategory[tmpdata$audio_type== 3 & tmpdata$variable== "deltaSad"], paired = FALSE)
# looking individually to t-test, and this is confirmed, delta sads ar different at au3.
tmpdata <- aggregate(deltaCategory~ audio_type + variable + participant_ID, groupEffects_audio_long,mean)
t.test(tmpdata$deltaCategory[tmpdata$audio_type== 2 & tmpdata$variable== "deltaHappy"],
tmpdata$deltaCategory[tmpdata$audio_type== 3 & tmpdata$variable== "deltaHappy"])
t.test(tmpdata$deltaCategory[tmpdata$audio_type== 2 & tmpdata$variable== "deltaSad"],
tmpdata$deltaCategory[tmpdata$audio_type== 3 & tmpdata$variable== "deltaSad"], paired = FALSE)
#
## GORKEM DEC PRE CHRISTMAS ANALYSES #
library(ggplot2)
library(rstatix)
#
## GORKEM DEC PRE CHRISTMAS ANALYSES #
library(ggplot2)
library(rstatix)
library(Rmisc)
rm(list=ls())
#
setwd("/Users/gorkem.er/Desktop/22Projects/CIG/CIG_03_A22")
cigdata = read.csv('CSI3_r3_cleaned.csv', header=TRUE)
#
subs = unique(cigdata$participant_ID)
cigdata = read.csv('CSI3_r3_cleaned.csv', header=TRUE)
number_of_sub <- length(unique(cigdata$participant_ID))
cigdataVP <- cigdata[cigdata$trial_type == "image-keyboard-response",] # or faceTrials <- cigdata[cigdata$stimulus == "magnitude_choice_original.jpg",]
head(cigdataVP$response)
# let's just get the relevant columns
cigdataVP = cigdataVP[,c("audio_type", "participant_ID", "faceTrialID", "response")]
head(cigdataVP)
cigdataVP$response <- as.numeric(cigdataVP$response)
head(cigdataVP$response)
cigdataVP_wide <- reshape(cigdataVP, idvar = c("participant_ID", "audio_type") , timevar = "faceTrialID", direction = "wide")
head(cigdataVP_wide)
# now let's make this our main data table.
cigdataVP_cleaned <- cigdataVP_wide #cigdataVP_wide[,c("participant_ID", "audio_type", "crowding_happy", "crowding_neutral", "crowding_sad")]
head(cigdataVP_cleaned)
# making it long back again
data_long <- melt(cigdataVP_cleaned, id.vars=c("participant_ID", "audio_type"))
head(data_long)
data_long$audio_type_dual <- ifelse(data_long$audio_type == 2, 2, 1)
cigdataVP_analyse <- data_long
# LETS CHECK IT AT JASP first #
write.csv(cigdataVP_analyse, "cigdataVP_analyse.csv")
# ok, laughter article-like wrangling.
# columns:
# visual context: single vs crowd
# facial expression: happy, neutral, sad
# simultaneous sound: crowdH, noise, crowdL
# average expression rating
rm(list=ls())
# ok, laughter article-like wrangling.
# columns:
# visual context: single vs crowd
# facial expression: happy, neutral, sad
# simultaneous sound: crowdH, noise, crowdL
# average expression rating
rm(list=ls())
cigdata = read.csv('CSI3_r3_cleaned.csv', header=TRUE)
#
subs = unique(cigdata$participant_ID)
number_of_sub <- length(unique(cigdata$participant_ID))
cigdataVP <- cigdata[cigdata$trial_type == "image-keyboard-response",] # or faceTrials <- cigdata[cigdata$stimulus == "magnitude_choice_original.jpg",]
head(cigdataVP$response)
cigdataVP$response <- as.numeric(cigdataVP$response)
head(cigdataVP)
cigdataVP$response <- as.numeric(cigdataVP$response)
cigdataVP_agg <- aggregate(response~faceTrialID + audio_type + participant_ID, cigdataVP, mean)
head(cigdataVP_agg)
# test
singles <- c("single_happy", "single_neutral", "single_sad")
crowds <- c("7_neutral_1_happy", "7_neutral_1_neutral", "7_neutral_1_sad")
cigdataVP_agg$visualContext = ifelse(cigdataVP_agg$faceTrialID %in% singles, "single", "crowd")
head(cigdataVP_agg)
happys <- c("single_happy", "7_neutral_1_happy")
neutrals <- c("single_neutral", "7_neutral_1_neutral")
sads <- c("single_sad", "7_neutral_1_sad")
cigdataVP_agg$facialExpression = ifelse(cigdataVP_agg$faceTrialID %in% happys, "happy", ifelse(cigdataVP_agg$faceTrialID %in% neutrals, "neutral", "sad"))
head(cigdataVP_agg)
cigdataVP_agg$simultaneousSound = ifelse(cigdataVP_agg$audio_type == 1, "Crowd_high", ifelse(cigdataVP_agg$audio_type == 2, "Noise", "Crowd_low"))
head(cigdataVP_agg)
cigdataVP_agg$simultaneousSoundC1N0 = ifelse(cigdataVP_agg$simultaneousSound == "Noise", "Noise", "Crowd")
cigdataVP_laughterLike <- cigdataVP_agg
write.csv(cigdataVP_laughterLike, "cigdataVP_laughterLike.csv")
# calculating individual means
single_happy_crowdH_dataset <- cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "single" & cigdataVP_laughterLike$facialExpression == "happy" & cigdataVP_laughterLike$simultaneousSound == "Crowd_high"]
single_happy_crowdH <- mean(cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "single" & cigdataVP_laughterLike$facialExpression == "happy" & cigdataVP_laughterLike$simultaneousSound == "Crowd_high"])
single_happy_crowdH
single_happy_noise_dataset <- cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "single" & cigdataVP_laughterLike$facialExpression == "happy" & cigdataVP_laughterLike$simultaneousSound == "Noise"]
single_happy_noise <- mean(cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "single" & cigdataVP_laughterLike$facialExpression == "happy" & cigdataVP_laughterLike$simultaneousSound == "Noise"])
single_happy_noise
single_happy_crowdH - single_happy_noise
single_neutral_crowdH_dataset <- cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "single" & cigdataVP_laughterLike$facialExpression == "neutral" & cigdataVP_laughterLike$simultaneousSound == "Crowd_high"]
single_neutral_crowdH <- mean(cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "single" & cigdataVP_laughterLike$facialExpression == "neutral" & cigdataVP_laughterLike$simultaneousSound == "Crowd_high"])
single_neutral_crowdH
single_neutral_noise_dataset <- cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "single" & cigdataVP_laughterLike$facialExpression == "neutral" & cigdataVP_laughterLike$simultaneousSound == "Noise"]
single_neutral_noise <- mean(cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "single" & cigdataVP_laughterLike$facialExpression == "neutral" & cigdataVP_laughterLike$simultaneousSound == "Noise"])
single_neutral_noise
single_neutral_crowdH - single_neutral_noise
single_sad_crowdH_dataset <- cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "single" & cigdataVP_laughterLike$facialExpression == "sad" & cigdataVP_laughterLike$simultaneousSound == "Crowd_high"]
single_sad_crowdH <- mean(cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "single" & cigdataVP_laughterLike$facialExpression == "sad" & cigdataVP_laughterLike$simultaneousSound == "Crowd_high"])
single_sad_crowdH
single_sad_noise_dataset <- cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "single" & cigdataVP_laughterLike$facialExpression == "sad" & cigdataVP_laughterLike$simultaneousSound == "Noise"]
single_sad_noise <- mean(cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "single" & cigdataVP_laughterLike$facialExpression == "sad" & cigdataVP_laughterLike$simultaneousSound == "Noise"])
single_sad_noise
single_sad_crowdH - single_sad_noise
# group
group_happy_crowdH_dataset <- cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "crowd" & cigdataVP_laughterLike$facialExpression == "happy" & cigdataVP_laughterLike$simultaneousSound == "Crowd_high"]
group_happy_crowdH <- mean(cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "crowd" & cigdataVP_laughterLike$facialExpression == "happy" & cigdataVP_laughterLike$simultaneousSound == "Crowd_high"])
group_happy_crowdH
group_happy_noise_dataset <- cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "crowd" & cigdataVP_laughterLike$facialExpression == "happy" & cigdataVP_laughterLike$simultaneousSound == "Noise"]
group_happy_noise <- mean(cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "crowd" & cigdataVP_laughterLike$facialExpression == "happy" & cigdataVP_laughterLike$simultaneousSound == "Noise"])
group_happy_noise
group_happy_crowdH - group_happy_noise
group_neutral_crowdH_dataset <- cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "crowd" & cigdataVP_laughterLike$facialExpression == "neutral" & cigdataVP_laughterLike$simultaneousSound == "Crowd_high"]
group_neutral_crowdH <- mean(cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "crowd" & cigdataVP_laughterLike$facialExpression == "neutral" & cigdataVP_laughterLike$simultaneousSound == "Crowd_high"])
group_neutral_crowdH
group_neutral_noise_dataset <- cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "crowd" & cigdataVP_laughterLike$facialExpression == "neutral" & cigdataVP_laughterLike$simultaneousSound == "Noise"]
group_neutral_noise <- mean(cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "crowd" & cigdataVP_laughterLike$facialExpression == "neutral" & cigdataVP_laughterLike$simultaneousSound == "Noise"])
group_neutral_noise
group_neutral_crowdH - group_neutral_noise
group_sad_crowdH_dataset <- cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "crowd" & cigdataVP_laughterLike$facialExpression == "sad" & cigdataVP_laughterLike$simultaneousSound == "Crowd_high"]
group_sad_crowdH <- mean(cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "crowd" & cigdataVP_laughterLike$facialExpression == "sad" & cigdataVP_laughterLike$simultaneousSound == "Crowd_high"])
group_sad_crowdH
group_sad_noise_dataset <- cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "crowd" & cigdataVP_laughterLike$facialExpression == "sad" & cigdataVP_laughterLike$simultaneousSound == "Noise"]
group_sad_noise <- mean(cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "crowd" & cigdataVP_laughterLike$facialExpression == "sad" & cigdataVP_laughterLike$simultaneousSound == "Noise"])
group_sad_noise
group_sad_crowdH - group_sad_noise
#
variable_names <- c(rep(c("single_happy"),each=length(single_happy_crowdH_dataset)), rep(c("single_neutral"),each=length(single_neutral_crowdH_dataset)), rep(c("single_sad"),each=length(single_sad_crowdH_dataset)),
rep(c("group_happy"),each=length(group_happy_crowdH_dataset)),rep(c("group_neutral"),each=length(group_neutral_crowdH_dataset)), rep(c("group_sad"),each=length(group_sad_crowdH_dataset)))
crowd_effects2 <- c(single_happy_crowdH_dataset, single_neutral_crowdH_dataset, single_sad_crowdH_dataset, group_happy_crowdH_dataset, group_neutral_crowdH_dataset, group_sad_crowdH_dataset)
new_df_audio1 <- data.frame(variable_names, crowd_effects2)
new_df_audio1 <- data.frame(variable_names, crowd_effects2)
# Key: Plotting
ggplot(new_df_audio1, aes(x=variable_names,y=crowd_effects2))+
geom_boxplot() + labs(title="Laughter style box plots") + geom_hline(yintercept = 5, linetype= 3) #+facet_wrap(~visualContext)
#barplot(new_df_audio1$crowd_effects2, names.arg = new_df_audio1$variable_names)
# acquriting SEM
tgc <- summarySE(new_df_audio1, measurevar="crowd_effects2", groupvars="variable_names")
# Key: Plotting
ggplot(new_df_audio1, aes(x=variable_names,y=crowd_effects2))+
geom_boxplot() + labs(title="Laughter style box plots") + geom_hline(yintercept = 5, linetype= 3) #+facet_wrap(~visualContext)
tgc <- summarySE(new_df_audio1, measurevar="crowd_effects2", groupvars="variable_names")
# The errorbars overlapped, so use position_dodge to move them horizontally
pd <- position_dodge(0.1) # move them .05 to the left and right
ggplot(tgc, aes(x=variable_names, y=crowd_effects2)) +
geom_errorbar(aes(ymin=crowd_effects2-se, ymax=crowd_effects2+se), width=.1, position=pd) +
geom_line(position=pd) +
geom_point(position=pd)
# doing it for the noise
variable_names <- c(rep(c("single_happy"),each=length(single_happy_noise_dataset)), rep(c("single_neutral"),each=length(single_neutral_noise_dataset)), rep(c("single_sad"),each=length(single_sad_noise_dataset)),
rep(c("group_happy"),each=length(group_happy_noise_dataset)),rep(c("group_neutral"),each=length(group_neutral_noise_dataset)), rep(c("group_sad"),each=length(group_sad_noise_dataset)))
crowd_effects2 <- c(single_happy_noise_dataset, single_neutral_noise_dataset, single_sad_noise_dataset, group_happy_noise_dataset, group_neutral_noise_dataset, group_sad_noise_dataset)
new_df_audio2 <- data.frame(variable_names, crowd_effects2)
new_df_audio2
tgc_audio2 <- summarySE(new_df_audio2, measurevar="crowd_effects2", groupvars="variable_names")
tgc_audio2
tgc
ggplot(tgc_audio2, aes(x=variable_names, y=crowd_effects2)) +
geom_errorbar(aes(ymin=crowd_effects2-se, ymax=crowd_effects2+se), width=.1, position=pd) +
geom_line(position=pd) +
geom_point(position=pd)
tgc_audio2$simultaneousSound <- "noise"
tgc$simultaneousSound <- "crowd_high"
new_df <- rbind(tgc, tgc_audio2)
ggplot(new_df, aes(x=variable_names, y=crowd_effects2, color = simultaneousSound)) +
geom_errorbar(aes(ymin=crowd_effects2-se, ymax=crowd_effects2+se), width=.1, position=pd) +
geom_line(position=pd) +
geom_point(position=pd)
new_df <- rbind(tgc, tgc_audio2)
# deltas? different from 0?
new_df_audio1$simultaneousSound <- "crowd"
new_df_audio2$simultaneousSound <- "noise"
new_df_audio2_sum <- summarySE(new_df_audio2, measurevar="crowd_effects2", groupvars=c("variable_names","simultaneousSound"))
#
merged_data <- rbind(new_df_audio1_sum, new_df_audio2_sum)
merged_data
tgc
ggplot(tgc_audio2, aes(x=variable_names, y=crowd_effects2)) +
geom_errorbar(aes(ymin=crowd_effects2-se, ymax=crowd_effects2+se), width=.1, position=pd) +
geom_line(position=pd) +
geom_point(position=pd)
tgc_audio2$simultaneousSound <- "noise"
tgc$simultaneousSound <- "crowd_high"
new_df <- rbind(tgc, tgc_audio2)
ggplot(new_df, aes(x=variable_names, y=crowd_effects2, color = simultaneousSound)) +
geom_errorbar(aes(ymin=crowd_effects2-se, ymax=crowd_effects2+se), width=.1, position=pd) +
geom_line(position=pd) +
geom_point(position=pd)
new_df <- rbind(tgc, tgc_audio2)
# deltas? different from 0?
new_df_audio1$simultaneousSound <- "crowd"
new_df_audio2$simultaneousSound <- "noise"
new_df_audio1_sum <- summarySE(new_df_audio1, measurevar="crowd_effects2", groupvars=c("variable_names","simultaneousSound"))
new_df_audio2_sum <- summarySE(new_df_audio2, measurevar="crowd_effects2", groupvars=c("variable_names","simultaneousSound"))
#
merged_data <- rbind(new_df_audio1_sum, new_df_audio2_sum)
merged_data
#### FIGURE 1 ####
plotReady <- aggregate(Diff~variable_names,
with(merged_data, data.frame(variable_names=variable_names, Diff=ifelse(simultaneousSound=="crowd", 1, -1)*crowd_effects2)), sum) # crowd is 1
#
merged_data <- rbind(new_df_audio1_sum, new_df_audio2_sum)
merged_data
#### FIGURE 3 ####
plotReady <- aggregate(Diff~variable_names,
with(merged_data, data.frame(variable_names=variable_names, Diff=ifelse(simultaneousSound=="crowd", 1, -1)*crowd_effects2)), sum) # crowd is 1
#### END OF FIGURE 3 ####
happys <- c("single_happy", "group_happy")
neutrals <- c("single_neutral", "group_neutral")
sads <- c("single_sad", "group_sad")
plotReady$facialExpressions <- ifelse(plotReady$variable_names %in% happys, "happy", ifelse(plotReady$variable_names %in% neutrals, "neutral", "sad"))
#### FIGURE 2 - WITH CROWD LOW ####
ggplot(plotReady, aes(x=variable_names,y=Diff, fill = factor(facialExpressions)))+
geom_bar(stat = "identity") + labs(title="Laughter style box plots") + geom_hline(yintercept = 0, linetype= 3) + theme_classic() +
scale_fill_manual(values=c("#E75F00", "#999999", "#56B4E9")) #+ facet_wrap(~facialExpressions)
#### END OF FIGURE 3 ####
happys <- c("single_happy", "group_happy")
neutrals <- c("single_neutral", "group_neutral")
sads <- c("single_sad", "group_sad")
plotReady$facialExpressions <- ifelse(plotReady$variable_names %in% happys, "happy", ifelse(plotReady$variable_names %in% neutrals, "neutral", "sad"))
#### FIGURE 4 - WITH CROWD LOW ####
ggplot(plotReady, aes(x=variable_names,y=Diff, fill = factor(facialExpressions)))+
geom_bar(stat = "identity") + labs(title="Laughter style box plots") + geom_hline(yintercept = 0, linetype= 3) + theme_classic() +
scale_fill_manual(values=c("#E75F00", "#999999", "#56B4E9")) #+ facet_wrap(~facialExpressions)
plotReady
# this is interesting because it shows that happy faces appear sadder and sad faces appear happier when grouped.
# also for the neutrals. This is interesting because it shows au1 - noise.
#### END OF FIGURE 4 ####
# adding crowd low condition
single_happy_crowdL_dataset <- cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "single" & cigdataVP_laughterLike$facialExpression == "happy" & cigdataVP_laughterLike$simultaneousSound == "Crowd_low"]
single_happy_crowdL <- mean(cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "single" & cigdataVP_laughterLike$facialExpression == "happy" & cigdataVP_laughterLike$simultaneousSound == "Crowd_low"])
single_happy_crowdL_dataset
single_neutral_crowdL_dataset <- cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "single" & cigdataVP_laughterLike$facialExpression == "neutral" & cigdataVP_laughterLike$simultaneousSound == "Crowd_low"]
single_neutral_crowdL <- mean(cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "single" & cigdataVP_laughterLike$facialExpression == "neutral" & cigdataVP_laughterLike$simultaneousSound == "Crowd_low"])
single_neutral_crowdL
single_sad_crowdL_dataset <- cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "single" & cigdataVP_laughterLike$facialExpression == "sad" & cigdataVP_laughterLike$simultaneousSound == "Crowd_low"]
single_sad_crowdL <- mean(cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "single" & cigdataVP_laughterLike$facialExpression == "sad" & cigdataVP_laughterLike$simultaneousSound == "Crowd_low"])
single_sad_crowdL
#
group_happy_crowdL_dataset <- cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "crowd" & cigdataVP_laughterLike$facialExpression == "happy" & cigdataVP_laughterLike$simultaneousSound == "Crowd_low"]
group_happy_crowdL <- mean(cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "crowd" & cigdataVP_laughterLike$facialExpression == "happy" & cigdataVP_laughterLike$simultaneousSound == "Crowd_low"])
group_happy_crowdL
group_neutral_crowdL_dataset <- cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "crowd" & cigdataVP_laughterLike$facialExpression == "neutral" & cigdataVP_laughterLike$simultaneousSound == "Crowd_low"]
group_neutral_crowdL <- mean(cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "crowd" & cigdataVP_laughterLike$facialExpression == "neutral" & cigdataVP_laughterLike$simultaneousSound == "Crowd_low"])
group_neutral_crowdL
group_sad_crowdL_dataset <- cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "crowd" & cigdataVP_laughterLike$facialExpression == "sad" & cigdataVP_laughterLike$simultaneousSound == "Crowd_low"]
group_sad_crowdL <- mean(cigdataVP_laughterLike$response[cigdataVP_laughterLike$visualContext == "crowd" & cigdataVP_laughterLike$facialExpression == "sad" & cigdataVP_laughterLike$simultaneousSound == "Crowd_low"])
group_sad_crowdL
#
variable_names <- c(rep(c("single_happy"),each=length(single_happy_crowdL_dataset)), rep(c("single_neutral"),each=length(single_neutral_crowdL_dataset)), rep(c("single_sad"),each=length(single_sad_crowdL_dataset)),
rep(c("group_happy"),each=length(group_happy_crowdL_dataset)),rep(c("group_neutral"),each=length(group_neutral_crowdL_dataset)), rep(c("group_sad"),each=length(group_sad_crowdL_dataset)))
crowd_effects2 <- c(single_happy_crowdL_dataset, single_neutral_crowdL_dataset, single_sad_crowdL_dataset, group_happy_crowdL_dataset, group_neutral_crowdL_dataset, group_sad_crowdL_dataset)
new_df_audio3 <- data.frame(variable_names, crowd_effects2)
new_df_audio3
new_df_audio3$simultaneousSound <- "crowd_low"
new_df_audio3_sum <- summarySE(new_df_audio3, measurevar="crowd_effects2", groupvars=c("variable_names","simultaneousSound"))
merged_data <- rbind(merged_data, new_df_audio3_sum)
merged_data
#
plotReady <- merged_data %>%
dcast(variable_names ~ simultaneousSound, value.var = "crowd_effects2", fill = 0) %>%
mutate(Diff = ((crowd+crowd_low)/2) - noise) %>%
select(variable_names, Diff)
#
happys <- c("single_happy", "group_happy")
neutrals <- c("single_neutral", "group_neutral")
sads <- c("single_sad", "group_sad")
plotReady$facialExpressions <- ifelse(plotReady$variable_names %in% happys, "happy", ifelse(plotReady$variable_names %in% neutrals, "neutral", "sad"))
ggplot(plotReady, aes(x=variable_names,y=Diff, fill = factor(facialExpressions)))+
geom_bar(stat = "identity") + labs(title="Laughter style box plots") + geom_hline(yintercept = 0, linetype= 3) + theme_classic() +
scale_fill_manual(values=c("#E75F00", "#999999", "#56B4E9")) #+ facet_wrap(~facialExpressions)
plotReady
# OK, so crowd audio makes sad faces appearing sadder, and sad-in-a-group more happier
# I'm not sure how to run a statistical analyses on this though. I have the mean and SD
# of the au1 and others but when I substract them what should I use for the sd. SEM?
#### End of Figure 5 ####
tgc_audio3 <- summarySE(new_df_audio3, measurevar="crowd_effects2", groupvars="variable_names")
tgc_audio3
tgc_audio3$simultaneousSound <- "crowd_low"
new_df <- rbind(tgc, tgc_audio2)
new_df <- rbind(new_df, tgc_audio3)
ggplot(new_df, aes(x=variable_names, y=crowd_effects2, color = simultaneousSound)) +
geom_errorbar(aes(ymin=crowd_effects2-se, ymax=crowd_effects2+se), width=.1, position=pd) +
geom_line(position=pd) +
geom_point(position=pd) + theme_classic()
